{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/mac/Desktop/PycharmProjects/TAADL/src')\n",
    "sys.path.insert(2, '/Users/mac/Desktop/PycharmProjects/TAADL/models')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from torch import optim\n",
    "from network import GPCopulaRNN\n",
    "from config import DATA_PATH, E_DICT\n",
    "from utils import transform, train_test_split, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess data\n",
    "prices_m = load_data('M')\n",
    "\n",
    "l_ret = np.log(prices_m/prices_m.shift()).fillna(0.0)\n",
    "z_tr, z_te = train_test_split(prices_m) \n",
    "x_tr, cdf  = transform(z_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# TODO: current CDF does not map the x to y correctly. output is just monotone increasing.\n",
    "# map the states accrodingly.\n",
    "\n",
    "class ECDF_(object):\n",
    "    def __init__(self, data:np.ndarray):\n",
    "        self.x = data \n",
    "        self.x_min, self.x_max = self.x.min(), self.x.max()\n",
    "        self.n = len(self.x)\n",
    "        self.y = np.linspace(1.0/self.n, 1.0, self.n)\n",
    "        self.f = interp1d(self.x, self.y, fill_value='extrapolate') # make interpolation\n",
    "        self.inv_f = interp1d(self.y, self.x, fill_value='extrapolate') # inverse is just arguments reversed\n",
    "        \n",
    "    def __call__(self, x_:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        calculates y given x under defined ECDF class.\n",
    "        \"\"\"\n",
    "        if np.sum(x_ > self.x_max) > 0 or np.sum(x_ < self.x_min) > 0:\n",
    "            x_ = np.where(x_ > self.x_max, self.x_max, x_)\n",
    "            x_ = np.where(x_ < self.x_min, self.x_min, x_)\n",
    "            print(x_)\n",
    "        return self.f(x_)\n",
    "\n",
    "    def inverse(self, y:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        calculates the inverse of ECDF with y as an input.\n",
    "        \"\"\"\n",
    "         # if cdf value is less than 0 or more than 1, trim values\n",
    "        if np.sum(y > 1.0) > 0 or np.sum(y < 0.0) > 0:\n",
    "            y = np.where(y > 1.0, 1.0, y)\n",
    "            y = np.where(y < 0.0, 0.0, y)\n",
    "        return self.inv_f(y) # otherwise, return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = ECDF_(z_tr[:,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.04308827, -0.02488683, -0.01671686, -0.00568048,\n",
       "        0.01038912,  0.03261695,  0.02982194,  0.01564011, -0.03088782,\n",
       "        0.01524771,  0.04128616,  0.05644295,  0.00198712,  0.03691364,\n",
       "        0.05079815, -0.03019079,  0.00714155,  0.01951302,  0.0296161 ,\n",
       "        0.00664789,  0.03818868,  0.03524607,  0.02959223,  0.01136696,\n",
       "       -0.01298764,  0.03322056,  0.0587876 ,  0.02152496, -0.00401167,\n",
       "       -0.0261666 , -0.00484038,  0.05023453,  0.04430554, -0.0338739 ,\n",
       "       -0.02488002, -0.0920969 , -0.00470977,  0.01168569,  0.04332916,\n",
       "        0.00409524, -0.09817712, -0.02605131, -0.04050545, -0.13189924,\n",
       "       -0.23888402, -0.06958473,  0.07415045, -0.15946335, -0.11271114,\n",
       "        0.07549214,  0.11995257,  0.12561159, -0.01895484,  0.10373427,\n",
       "        0.05259912,  0.0491927 , -0.02309832,  0.04338939, -0.00184333,\n",
       "       -0.06824145, -0.01021957,  0.06241927, -0.04018088, -0.12077456,\n",
       "       -0.01906217,  0.12937592, -0.04852358,  0.1075642 ,  0.04570333,\n",
       "       -0.08531509,  0.08323733,  0.04310005,  0.03026192, -0.01070283,\n",
       "        0.08081515, -0.0336432 , -0.01894239, -0.04844548, -0.10289729,\n",
       "       -0.12656468,  0.11684131, -0.03119041, -0.01885827,  0.05309962,\n",
       "        0.04935205, -0.00080298, -0.02466551, -0.12587714,  0.07608679,\n",
       "        0.00591692,  0.04357949,  0.03086574,  0.01656506,  0.02263445,\n",
       "        0.04024854,  0.04478354, -0.03516069,  0.00075567,  0.04409039,\n",
       "        0.00144481, -0.04686401,  0.0750476 , -0.01544061,  0.07017523,\n",
       "        0.04020534,  0.00888725,  0.02841466, -0.04703211,  0.06953774,\n",
       "       -0.00516478,  0.02697341,  0.00763201, -0.00193236, -0.04312366,\n",
       "        0.00600061, -0.03744456, -0.02220534,  0.01998474, -0.04940236,\n",
       "        0.00469178,  0.05818463, -0.02277888,  0.04007195,  0.00260053,\n",
       "       -0.03559176,  0.0239506 , -0.07340401, -0.04471403,  0.05926422,\n",
       "       -0.01406981, -0.03168603, -0.05509288, -0.03157871,  0.06142385,\n",
       "        0.03022148, -0.00847015, -0.03293885,  0.03023432,  0.00486617,\n",
       "        0.00611315, -0.03225654, -0.02523054,  0.05044289], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_tr[:,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00694444, 0.01388889, 0.02083333, 0.02777778, 0.03472222,\n",
       "       0.04166667, 0.04861111, 0.05555556, 0.0625    , 0.06944444,\n",
       "       0.07638889, 0.08333333, 0.09027778, 0.09722222, 0.10416667,\n",
       "       0.11111111, 0.11805556, 0.125     , 0.13194444, 0.13888889,\n",
       "       0.14583333, 0.15277778, 0.15972222, 0.16666667, 0.17361111,\n",
       "       0.18055556, 0.1875    , 0.19444444, 0.20138889, 0.20833333,\n",
       "       0.21527778, 0.22222222, 0.22916667, 0.23611111, 0.24305556,\n",
       "       0.25      , 0.25694444, 0.26388889, 0.27083333, 0.27777778,\n",
       "       0.28472222, 0.29166667, 0.29861111, 0.30555556, 0.3125    ,\n",
       "       0.31944444, 0.32638889, 0.33333333, 0.34027778, 0.34722222,\n",
       "       0.35416667, 0.36111111, 0.36805556, 0.375     , 0.38194444,\n",
       "       0.38888889, 0.39583333, 0.40277778, 0.40972222, 0.41666667,\n",
       "       0.42361111, 0.43055556, 0.4375    , 0.44444444, 0.45138889,\n",
       "       0.45833333, 0.46527778, 0.47222222, 0.47916667, 0.48611111,\n",
       "       0.49305556, 0.5       , 0.50694444, 0.51388889, 0.52083333,\n",
       "       0.52777778, 0.53472222, 0.54166667, 0.54861111, 0.55555556,\n",
       "       0.5625    , 0.56944444, 0.57638889, 0.58333333, 0.59027778,\n",
       "       0.59722222, 0.60416667, 0.61111111, 0.61805556, 0.625     ,\n",
       "       0.63194444, 0.63888889, 0.64583333, 0.65277778, 0.65972222,\n",
       "       0.66666667, 0.67361111, 0.68055556, 0.6875    , 0.69444444,\n",
       "       0.70138889, 0.70833333, 0.71527778, 0.72222222, 0.72916667,\n",
       "       0.73611111, 0.74305556, 0.75      , 0.75694444, 0.76388889,\n",
       "       0.77083333, 0.77777778, 0.78472222, 0.79166667, 0.79861111,\n",
       "       0.80555556, 0.8125    , 0.81944444, 0.82638889, 0.83333333,\n",
       "       0.84027778, 0.84722222, 0.85416667, 0.86111111, 0.86805556,\n",
       "       0.875     , 0.88194444, 0.88888889, 0.89583333, 0.90277778,\n",
       "       0.90972222, 0.91666667, 0.92361111, 0.93055556, 0.9375    ,\n",
       "       0.94444444, 0.95138889, 0.95833333, 0.96527778, 0.97222222,\n",
       "       0.97916667, 0.98611111, 0.99305556, 1.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = cdf(z_tr[:,0].numpy())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add mean and covariance to existing RP strategy and do the plotting\n",
    "params = torch.load('/Users/mac/Desktop/PycharmProjects/TAADL/models/GaussCopula.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 20\n",
    "num_epochs = 250\n",
    "\n",
    "# load parameters for model and optimizer\n",
    "model = GPCopulaRNN(input_size=1, hidden_size=4, num_layers=2, rank_size=5, \n",
    "                        batch_size=3, num_asset=7, dropout=0.05, features=e_dict)\n",
    "model.load_state_dict(params['net_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_assets = 7\n",
    "hidden_size = 4\n",
    "seq_length = 12\n",
    "batch_size = 1\n",
    "\n",
    "lstm = nn.LSTM(input_size=1, hidden_size=hidden_size,\n",
    "                    num_layers=num_layers, batch_first=False) # num_batch x seq_len x num_feature\n",
    "\n",
    "\n",
    "h0, c0 = torch.zeros(num_layers, batch_size, hidden_size), torch.zeros(num_layers, batch_size, hidden_size)\n",
    "test = torch.rand(12,1,7)\n",
    "\n",
    "outputs = []\n",
    "for i in range(test.size(2)):\n",
    "    output, (hn, cn) = lstm(test[:,:,i].unsqueeze(2), (h0,c0))\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0681,  0.0067, -0.0214, -0.0057]],\n",
       "\n",
       "        [[-0.0961,  0.0206, -0.0354, -0.0099]],\n",
       "\n",
       "        [[-0.1068,  0.0381, -0.0508, -0.0132]],\n",
       "\n",
       "        [[-0.1140,  0.0494, -0.0518, -0.0170]],\n",
       "\n",
       "        [[-0.1176,  0.0581, -0.0528, -0.0192]],\n",
       "\n",
       "        [[-0.1196,  0.0651, -0.0544, -0.0205]],\n",
       "\n",
       "        [[-0.1218,  0.0669, -0.0496, -0.0210]],\n",
       "\n",
       "        [[-0.1227,  0.0690, -0.0489, -0.0205]],\n",
       "\n",
       "        [[-0.1237,  0.0689, -0.0462, -0.0197]],\n",
       "\n",
       "        [[-0.1240,  0.0708, -0.0481, -0.0191]],\n",
       "\n",
       "        [[-0.1241,  0.0742, -0.0524, -0.0195]],\n",
       "\n",
       "        [[-0.1249,  0.0749, -0.0512, -0.0210]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.permute(0,2,1)\n",
    "h0_2, c0_2 = torch.zeros(num_layers, seq_length, hidden_size), torch.zeros(num_layers, seq_length, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = nn.LSTM(input_size=1, hidden_size=hidden_size,\n",
    "                num_layers=num_layers, batch_first=True)\n",
    "\n",
    "output2, (hn_2, cn_2) = lstm2(test2, (h0_2,c0_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 7, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0681,  0.0067, -0.0214, -0.0057]],\n",
       "\n",
       "        [[-0.0961,  0.0206, -0.0354, -0.0099]],\n",
       "\n",
       "        [[-0.1068,  0.0381, -0.0508, -0.0132]],\n",
       "\n",
       "        [[-0.1140,  0.0494, -0.0518, -0.0170]],\n",
       "\n",
       "        [[-0.1176,  0.0581, -0.0528, -0.0192]],\n",
       "\n",
       "        [[-0.1196,  0.0651, -0.0544, -0.0205]],\n",
       "\n",
       "        [[-0.1218,  0.0669, -0.0496, -0.0210]],\n",
       "\n",
       "        [[-0.1227,  0.0690, -0.0489, -0.0205]],\n",
       "\n",
       "        [[-0.1237,  0.0689, -0.0462, -0.0197]],\n",
       "\n",
       "        [[-0.1240,  0.0708, -0.0481, -0.0191]],\n",
       "\n",
       "        [[-0.1241,  0.0742, -0.0524, -0.0195]],\n",
       "\n",
       "        [[-0.1249,  0.0749, -0.0512, -0.0210]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0227, -0.1578,  0.0350, -0.0186],\n",
       "        [-0.0089, -0.1551,  0.0307, -0.0177],\n",
       "        [-0.0150, -0.1564,  0.0326, -0.0181],\n",
       "        [-0.0154, -0.1564,  0.0327, -0.0182],\n",
       "        [-0.0251, -0.1583,  0.0357, -0.0188],\n",
       "        [-0.0039, -0.1540,  0.0290, -0.0174],\n",
       "        [-0.0107, -0.1555,  0.0312, -0.0179],\n",
       "        [-0.0307, -0.1592,  0.0373, -0.0191],\n",
       "        [-0.0148, -0.1563,  0.0325, -0.0181],\n",
       "        [-0.0087, -0.1551,  0.0306, -0.0177],\n",
       "        [-0.0041, -0.1540,  0.0290, -0.0174],\n",
       "        [-0.0070, -0.1547,  0.0300, -0.0176]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0684,  0.0060, -0.0201, -0.0054]],\n",
       "\n",
       "        [[-0.0970,  0.0173, -0.0299, -0.0087]],\n",
       "\n",
       "        [[-0.1083,  0.0314, -0.0402, -0.0111]],\n",
       "\n",
       "        [[-0.1133,  0.0456, -0.0501, -0.0136]],\n",
       "\n",
       "        [[-0.1173,  0.0551, -0.0515, -0.0166]],\n",
       "\n",
       "        [[-0.1191,  0.0639, -0.0555, -0.0188]],\n",
       "\n",
       "        [[-0.1207,  0.0702, -0.0572, -0.0210]],\n",
       "\n",
       "        [[-0.1208,  0.0779, -0.0639, -0.0225]],\n",
       "\n",
       "        [[-0.1227,  0.0797, -0.0600, -0.0251]],\n",
       "\n",
       "        [[-0.1231,  0.0828, -0.0613, -0.0262]],\n",
       "\n",
       "        [[-0.1230,  0.0868, -0.0656, -0.0271]],\n",
       "\n",
       "        [[-0.1240,  0.0876, -0.0636, -0.0290]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0071, -0.2588,  0.0495, -0.0176],\n",
       "        [ 0.0045, -0.2580,  0.0460, -0.0176],\n",
       "        [ 0.0022, -0.2579,  0.0467, -0.0174],\n",
       "        [ 0.0033, -0.2577,  0.0463, -0.0173],\n",
       "        [-0.0081, -0.2588,  0.0497, -0.0175],\n",
       "        [ 0.0308, -0.2528,  0.0364, -0.0158],\n",
       "        [ 0.0159, -0.2556,  0.0419, -0.0166],\n",
       "        [ 0.0029, -0.2556,  0.0453, -0.0162],\n",
       "        [ 0.0171, -0.2547,  0.0412, -0.0162],\n",
       "        [ 0.0173, -0.2555,  0.0415, -0.0166],\n",
       "        [ 0.0136, -0.2567,  0.0429, -0.0172],\n",
       "        [ 0.0261, -0.2536,  0.0381, -0.0160]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fcdd98ffdc43e19459281bdd6dd2d99dc416cd8bc0df76bf27c994662bebc1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
