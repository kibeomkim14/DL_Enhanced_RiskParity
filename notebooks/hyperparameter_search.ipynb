{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Desktop/PycharmProjects/TAADL/notebooks/hyperparameter_search.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Desktop/PycharmProjects/TAADL/notebooks/hyperparameter_search.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptuna\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Desktop/PycharmProjects/TAADL/notebooks/hyperparameter_search.ipynb#ch0000000?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Desktop/PycharmProjects/TAADL/notebooks/hyperparameter_search.ipynb#ch0000000?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msplit\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from datetime import datetime, timedelta\n",
    "from src.split import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature data\n",
    "feature = pd.read_csv('/Users/mac/Desktop/PycharmProjects/TAADL/DATA/features.csv', index_col='Date')\n",
    "feature.index = pd.to_datetime(feature.index)\n",
    "tr_x, tr_y, val_x, val_y, te_data = train_test_split(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data:pd.DataFrame, valid_ratio:float=0.2, train_ratio:float=0.6):\n",
    "    # we will use 60% of the data as train+val set. this data will be used to tune DL model.\n",
    "    n = data.shape[0]\n",
    "    tr_idx  = int(n * train_ratio)\n",
    "    val_idx = int(tr_idx * (1-valid_ratio))\n",
    "\n",
    "    # split the dataset according to tr index\n",
    "    tr_data = data.iloc[:tr_idx]\n",
    "    te_data = data.iloc[tr_idx:]\n",
    "\n",
    "    # Now we create a target for training a DL model. Target will be a future 130-days return of each ETF products.\n",
    "    # To make a target we look 130 days ahead of the training set. This will be done by shifting the view by 130 days.\n",
    "    target_list = ['BNDX_ret130','BND_ret130','VGK_ret130','VNQI_ret130',\n",
    "                    'VNQ_ret130','VTI_ret130','VWOB_ret130','VWO_ret130']\n",
    "    target = feature.iloc[130:tr_idx+130][target_list]\n",
    "\n",
    "    # add prefix on columns and reset the\n",
    "    target = target.add_prefix('targ_')\n",
    "    target.index = tr_data.index\n",
    "\n",
    "    assert tr_data.shape[0] == target.shape[0], 'feature shape and target shape is not same.'\n",
    "    mu, std = tr_data.mean(axis=0), tr_data.std(axis=0)\n",
    "    tr_data = tr_data.sub(mu).div(std) # normalize the data along rows\n",
    "\n",
    "    trn_features, trn_label = tr_data.iloc[:val_idx-130], target.iloc[:val_idx-130] # cut last few days of data to prevent data leakage.\n",
    "    val_features, val_label = tr_data.iloc[val_idx:], target.iloc[val_idx:]\n",
    "\n",
    "    print(trn_features.shape, trn_label.shape)\n",
    "    print(val_features.shape, val_label.shape)\n",
    "    return trn_features, trn_label, val_features, val_label, te_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1702, 46) (1702, 8)\n",
      "(458, 46) (458, 8)\n"
     ]
    }
   ],
   "source": [
    "tr_x, tr_y, val_x, val_y, te_data = train_test_split(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 파트는 향후 6개월의 예상 수익률을 예측하는 것을 output 으로 목표로 하고 training, validation set 을 이용해 MLP 를 학습시켜 주는 것입니다.\n",
    "여기서는 Cross-validation 이 아닌 Walk-forward method 를 이용해서 데이터가 점진적으로 늘어나는 세팅을 사용하였고, batch 의 약 30%는 validation set 으로 loss 를 계산했습니다. \n",
    "\n",
    "hyperparameter 중 몇 개는 논문 원문에서 가져왔고, model update epoch 는 임의로 설정했습니다. (여기서는 `n=30`) 그 외의 hyperparameter 는 `optuna`를 이용하여 validation loss 가 낮아지는 것을 objective 로 두고 search 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:07,705]\u001b[0m A new study created in memory with name: no-name-75ad5053-a23a-42ce-8af0-a15d0d13704d\u001b[0m\n",
      "\u001b[32m[I 2022-02-26 17:48:10,512]\u001b[0m Trial 0 finished with value: 0.06572332978248596 and parameters: {'learning rate': 0.004931038571464121, 'weight decay': 1.3934813638959082e-05, 'epsilon': 0.060871899363027296}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.17898411806672812, Test Loss: 0.06572332978248596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:12,600]\u001b[0m Trial 1 finished with value: 0.2250470221042633 and parameters: {'learning rate': 0.003330843820651318, 'weight decay': 0.006494655367292259, 'epsilon': 0.48000629719415866}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.7733308918774128, Test Loss: 0.2250470221042633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:14,722]\u001b[0m Trial 2 finished with value: 0.41273871064186096 and parameters: {'learning rate': 0.003179561548618473, 'weight decay': 3.1712238082907e-06, 'epsilon': 0.7079124731989297}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.9591492891311646, Test Loss: 0.41273871064186096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:16,863]\u001b[0m Trial 3 finished with value: 8.787087440490723 and parameters: {'learning rate': 1.7982439768548158e-05, 'weight decay': 0.00432091989049411, 'epsilon': 0.8306730287649381}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 15.830010509490966, Test Loss: 8.787087440490723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:18,905]\u001b[0m Trial 4 finished with value: 8.279088020324707 and parameters: {'learning rate': 3.727311806797103e-06, 'weight decay': 3.7156158507745716e-06, 'epsilon': 0.6178906954982945}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 12.38615255355835, Test Loss: 8.279088020324707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:21,030]\u001b[0m Trial 5 finished with value: 7.600217819213867 and parameters: {'learning rate': 3.0668502948325048e-06, 'weight decay': 1.4168945304527704e-06, 'epsilon': 0.2444690561132642}. Best is trial 0 with value: 0.06572332978248596.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 12.024067783355713, Test Loss: 7.600217819213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:23,023]\u001b[0m Trial 6 finished with value: 0.042233653366565704 and parameters: {'learning rate': 0.002776788711029991, 'weight decay': 0.015381557137072004, 'epsilon': 0.09572574469461623}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.26760793216526507, Test Loss: 0.042233653366565704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:25,128]\u001b[0m Trial 7 finished with value: 0.6609663367271423 and parameters: {'learning rate': 0.00085491922463903, 'weight decay': 1.238926400879728e-06, 'epsilon': 0.2772771498489291}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.5530569970607757, Test Loss: 0.6609663367271423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:27,769]\u001b[0m Trial 8 finished with value: 2.0406036376953125 and parameters: {'learning rate': 0.00022861696631358246, 'weight decay': 0.012415973863291936, 'epsilon': 0.34781762636738706}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 5.519203233718872, Test Loss: 2.0406036376953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:30,100]\u001b[0m Trial 9 finished with value: 0.38689252734184265 and parameters: {'learning rate': 0.0006586249447912442, 'weight decay': 0.00015929460548149161, 'epsilon': 0.04586192023871559}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.9507211402058602, Test Loss: 0.38689252734184265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:32,338]\u001b[0m Trial 10 finished with value: 2.544936180114746 and parameters: {'learning rate': 5.542452288989e-05, 'weight decay': 0.000834318135213371, 'epsilon': 0.001957216971786885}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 5.892043423652649, Test Loss: 2.544936180114746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:34,188]\u001b[0m Trial 11 finished with value: 0.1368415653705597 and parameters: {'learning rate': 0.004701972047463136, 'weight decay': 8.977922612263304e-05, 'epsilon': 0.1472202064763719}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.28831139132380484, Test Loss: 0.1368415653705597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:36,008]\u001b[0m Trial 12 finished with value: 1.3433336019515991 and parameters: {'learning rate': 0.0007231774394685213, 'weight decay': 1.864583828899371e-05, 'epsilon': 0.9777053689406484}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 3.5191673636436462, Test Loss: 1.3433336019515991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:37,848]\u001b[0m Trial 13 finished with value: 2.8740074634552 and parameters: {'learning rate': 0.00014912823844421367, 'weight decay': 3.67191921383068e-05, 'epsilon': 0.4230893833701819}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 6.331141996383667, Test Loss: 2.8740074634552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:39,698]\u001b[0m Trial 14 finished with value: 0.28232958912849426 and parameters: {'learning rate': 0.001691389127845777, 'weight decay': 0.0008406781588997542, 'epsilon': 0.15139223509060573}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.5890150651335716, Test Loss: 0.28232958912849426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:41,731]\u001b[0m Trial 15 finished with value: 1.2060542106628418 and parameters: {'learning rate': 0.00030232857821638594, 'weight decay': 0.0011408432215261153, 'epsilon': 0.15551493849734166}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 2.7984665870666503, Test Loss: 1.2060542106628418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:43,512]\u001b[0m Trial 16 finished with value: 5.25287389755249 and parameters: {'learning rate': 3.530910972569355e-05, 'weight decay': 1.5136143527623182e-05, 'epsilon': 0.06737901228383836}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 10.08700180053711, Test Loss: 5.25287389755249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:45,330]\u001b[0m Trial 17 finished with value: 0.46103501319885254 and parameters: {'learning rate': 0.0016115665418924296, 'weight decay': 0.0003359168799324976, 'epsilon': 0.31604349106651786}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.2324285894632339, Test Loss: 0.46103501319885254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:47,199]\u001b[0m Trial 18 finished with value: 10.020800590515137 and parameters: {'learning rate': 1.0157826273809347e-05, 'weight decay': 0.022825563210979498, 'epsilon': 0.5849800236987925}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 19.117963600158692, Test Loss: 10.020800590515137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:49,033]\u001b[0m Trial 19 finished with value: 2.6920862197875977 and parameters: {'learning rate': 0.00011773406337070084, 'weight decay': 8.355139672487604e-06, 'epsilon': 0.15031578471993556}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 6.252894306182862, Test Loss: 2.6920862197875977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:50,799]\u001b[0m Trial 20 finished with value: 1.6985007524490356 and parameters: {'learning rate': 0.0003662569275293754, 'weight decay': 7.899866142217974e-05, 'epsilon': 0.3781333564492842}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 3.838569867610931, Test Loss: 1.6985007524490356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:52,649]\u001b[0m Trial 21 finished with value: 0.13061431050300598 and parameters: {'learning rate': 0.004988610017070124, 'weight decay': 6.6812743591077e-05, 'epsilon': 0.2017852306431351}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3283512469381094, Test Loss: 0.13061431050300598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:54,496]\u001b[0m Trial 22 finished with value: 0.31656330823898315 and parameters: {'learning rate': 0.0017973821502526629, 'weight decay': 3.9140004042397264e-05, 'epsilon': 0.22316119840090098}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.8153097674250602, Test Loss: 0.31656330823898315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:56,300]\u001b[0m Trial 23 finished with value: 0.0847037062048912 and parameters: {'learning rate': 0.004559365794940608, 'weight decay': 0.000282479662875785, 'epsilon': 0.07656060750361249}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.19801185503602028, Test Loss: 0.0847037062048912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:58,073]\u001b[0m Trial 24 finished with value: 0.22733232378959656 and parameters: {'learning rate': 0.0013040022680214673, 'weight decay': 0.002120609880035797, 'epsilon': 0.0626594203426017}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.5791842445731163, Test Loss: 0.22733232378959656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:48:59,879]\u001b[0m Trial 25 finished with value: 0.06692373007535934 and parameters: {'learning rate': 0.00273825135812326, 'weight decay': 0.0003105960005226536, 'epsilon': 0.0017611363112202127}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.15489877052605153, Test Loss: 0.06692373007535934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:01,725]\u001b[0m Trial 26 finished with value: 8.341145515441895 and parameters: {'learning rate': 1.229622719029386e-06, 'weight decay': 0.0032824555649557043, 'epsilon': 0.0335173403411776}. Best is trial 6 with value: 0.042233653366565704.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 13.871122932434082, Test Loss: 8.341145515441895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:03,528]\u001b[0m Trial 27 finished with value: 0.03158019110560417 and parameters: {'learning rate': 0.0025191521841222467, 'weight decay': 0.02847479047998436, 'epsilon': 0.10940744022263169}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2172734433785081, Test Loss: 0.03158019110560417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:05,290]\u001b[0m Trial 28 finished with value: 0.6270871758460999 and parameters: {'learning rate': 0.0005088637904449621, 'weight decay': 0.024463536158727057, 'epsilon': 0.12309211797354064}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.6919302999973298, Test Loss: 0.6270871758460999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:07,388]\u001b[0m Trial 29 finished with value: 0.7037527561187744 and parameters: {'learning rate': 0.0011290775641213547, 'weight decay': 0.009480209929518538, 'epsilon': 0.4527306157502107}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.997828134894371, Test Loss: 0.7037527561187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:09,208]\u001b[0m Trial 30 finished with value: 0.28271597623825073 and parameters: {'learning rate': 0.002546200497768773, 'weight decay': 0.011132898108675668, 'epsilon': 0.5489714176824072}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.9765442118048668, Test Loss: 0.28271597623825073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:10,965]\u001b[0m Trial 31 finished with value: 0.03405940532684326 and parameters: {'learning rate': 0.002579842303443435, 'weight decay': 0.0019568580283189957, 'epsilon': 0.0039679694172758545}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.09522737450897693, Test Loss: 0.03405940532684326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:12,840]\u001b[0m Trial 32 finished with value: 0.10104215145111084 and parameters: {'learning rate': 0.0025885422912737166, 'weight decay': 0.0056968805515227525, 'epsilon': 0.09590650856749024}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3351199090480804, Test Loss: 0.10104215145111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:14,707]\u001b[0m Trial 33 finished with value: 0.20657503604888916 and parameters: {'learning rate': 0.002986664336452943, 'weight decay': 0.0020963637184044097, 'epsilon': 0.23029636586991775}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.5311173141002655, Test Loss: 0.20657503604888916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:16,548]\u001b[0m Trial 34 finished with value: 1.162754774093628 and parameters: {'learning rate': 0.0010845301363668974, 'weight decay': 0.025232274910657323, 'epsilon': 0.7543973935897876}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 2.973889797925949, Test Loss: 1.162754774093628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:18,348]\u001b[0m Trial 35 finished with value: 0.27595216035842896 and parameters: {'learning rate': 0.002000837366316953, 'weight decay': 0.01460397789797703, 'epsilon': 0.28963178877039114}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.740600124001503, Test Loss: 0.27595216035842896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:20,192]\u001b[0m Trial 36 finished with value: 0.7702469229698181 and parameters: {'learning rate': 0.0004772623417979221, 'weight decay': 0.006613188415583833, 'epsilon': 0.1999651619223991}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 2.294750618934631, Test Loss: 0.7702469229698181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:22,031]\u001b[0m Trial 37 finished with value: 0.07941995561122894 and parameters: {'learning rate': 0.00406100802544161, 'weight decay': 4.318365543276894e-06, 'epsilon': 0.1111000775106927}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.27486950531601906, Test Loss: 0.07941995561122894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:23,871]\u001b[0m Trial 38 finished with value: 0.12078291177749634 and parameters: {'learning rate': 0.0008940274303945916, 'weight decay': 0.002563407288112723, 'epsilon': 0.00693146814520805}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.4201589960604906, Test Loss: 0.12078291177749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:25,649]\u001b[0m Trial 39 finished with value: 2.7768590450286865 and parameters: {'learning rate': 0.0002167483968750612, 'weight decay': 0.005418789180461991, 'epsilon': 0.6554268004485934}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 6.1641898393630985, Test Loss: 2.7768590450286865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:27,477]\u001b[0m Trial 40 finished with value: 8.148659706115723 and parameters: {'learning rate': 1.2454489948088658e-05, 'weight decay': 0.015857056746626942, 'epsilon': 0.17379790542669185}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 14.57155475616455, Test Loss: 8.148659706115723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:29,293]\u001b[0m Trial 41 finished with value: 0.08880815654993057 and parameters: {'learning rate': 0.002811916406084804, 'weight decay': 0.0004225031549359103, 'epsilon': 0.009850570085158838}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2399714481085539, Test Loss: 0.08880815654993057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:31,041]\u001b[0m Trial 42 finished with value: 0.11294437199831009 and parameters: {'learning rate': 0.0030560611637852307, 'weight decay': 0.0006368058646249705, 'epsilon': 0.08229325389743604}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3015517875552177, Test Loss: 0.11294437199831009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:32,922]\u001b[0m Trial 43 finished with value: 0.15200525522232056 and parameters: {'learning rate': 0.00212527718135779, 'weight decay': 0.001420747293767099, 'epsilon': 0.051811561913438504}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.40933132022619245, Test Loss: 0.15200525522232056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:34,725]\u001b[0m Trial 44 finished with value: 0.2745673358440399 and parameters: {'learning rate': 0.0007007330451816303, 'weight decay': 2.1869147020499084e-06, 'epsilon': 0.003619148608431446}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.6364093333482742, Test Loss: 0.2745673358440399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:36,512]\u001b[0m Trial 45 finished with value: 0.5374910831451416 and parameters: {'learning rate': 0.0013020311516802963, 'weight decay': 0.0001587222368189854, 'epsilon': 0.265729380559554}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.0487255126237869, Test Loss: 0.5374910831451416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:38,484]\u001b[0m Trial 46 finished with value: 0.10379644483327866 and parameters: {'learning rate': 0.003854798837964946, 'weight decay': 0.00018080008121900865, 'epsilon': 0.11182329212028318}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2479759484529495, Test Loss: 0.10379644483327866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:40,320]\u001b[0m Trial 47 finished with value: 0.06463777273893356 and parameters: {'learning rate': 0.001643271280037049, 'weight decay': 0.008723436998592396, 'epsilon': 0.034108861253072636}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2900690294802189, Test Loss: 0.06463777273893356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:42,137]\u001b[0m Trial 48 finished with value: 0.8600147366523743 and parameters: {'learning rate': 0.001558640714726731, 'weight decay': 0.008270341634409269, 'epsilon': 0.9658641631483225}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 2.152132201194763, Test Loss: 0.8600147366523743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:43,956]\u001b[0m Trial 49 finished with value: 4.532379627227783 and parameters: {'learning rate': 5.1755980187584956e-05, 'weight decay': 0.004012307780369468, 'epsilon': 0.18544459239296052}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 9.80882740020752, Test Loss: 4.532379627227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:45,710]\u001b[0m Trial 50 finished with value: 0.5977969765663147 and parameters: {'learning rate': 0.0009753546692313549, 'weight decay': 0.016538901410610908, 'epsilon': 0.3637038646490094}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.763415789604187, Test Loss: 0.5977969765663147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:47,513]\u001b[0m Trial 51 finished with value: 0.07798724621534348 and parameters: {'learning rate': 0.003354117093510323, 'weight decay': 0.001442354728240929, 'epsilon': 0.04271927813437926}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.183421696908772, Test Loss: 0.07798724621534348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:49,344]\u001b[0m Trial 52 finished with value: 0.051292963325977325 and parameters: {'learning rate': 0.0020769756801155737, 'weight decay': 0.026099673788859832, 'epsilon': 0.13331811535469076}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.4664541933685541, Test Loss: 0.051292963325977325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:51,073]\u001b[0m Trial 53 finished with value: 0.12434007227420807 and parameters: {'learning rate': 0.001958097083043451, 'weight decay': 0.02295037546338824, 'epsilon': 0.13210940722203002}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.5118302673101425, Test Loss: 0.12434007227420807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:52,973]\u001b[0m Trial 54 finished with value: 0.5082242488861084 and parameters: {'learning rate': 0.0005239801345081354, 'weight decay': 0.028684926975139583, 'epsilon': 0.09483002244247721}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.6196550756692887, Test Loss: 0.5082242488861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:54,892]\u001b[0m Trial 55 finished with value: 0.04526921361684799 and parameters: {'learning rate': 0.0048918415620223974, 'weight decay': 0.00905014479047002, 'epsilon': 0.1516622105010734}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2603473035618663, Test Loss: 0.04526921361684799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:56,691]\u001b[0m Trial 56 finished with value: 0.2770697772502899 and parameters: {'learning rate': 0.00146130525950331, 'weight decay': 0.00822361439853971, 'epsilon': 0.16125261264962643}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.7696662992238998, Test Loss: 0.2770697772502899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:49:58,570]\u001b[0m Trial 57 finished with value: 0.06066317856311798 and parameters: {'learning rate': 0.004534050577473257, 'weight decay': 0.01544656900604002, 'epsilon': 0.31016524918147526}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2526424240320921, Test Loss: 0.06066317856311798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:00,369]\u001b[0m Trial 58 finished with value: 0.09241533279418945 and parameters: {'learning rate': 0.0040247698780852105, 'weight decay': 0.016474853185173503, 'epsilon': 0.3371191548975413}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3424352966248989, Test Loss: 0.09241533279418945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:02,342]\u001b[0m Trial 59 finished with value: 0.08469107002019882 and parameters: {'learning rate': 0.004406166096194078, 'weight decay': 0.012564749498898835, 'epsilon': 0.28372909359120024}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3976104646921158, Test Loss: 0.08469107002019882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:04,174]\u001b[0m Trial 60 finished with value: 0.17934121191501617 and parameters: {'learning rate': 0.0021848610342009344, 'weight decay': 0.003725559560477907, 'epsilon': 0.227342154199766}. Best is trial 27 with value: 0.03158019110560417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.5944272130727768, Test Loss: 0.17934121191501617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:05,935]\u001b[0m Trial 61 finished with value: 0.009599674493074417 and parameters: {'learning rate': 0.004907677251468682, 'weight decay': 0.01887513742510077, 'epsilon': 0.048959443291259196}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.06046841787174344, Test Loss: 0.009599674493074417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:07,802]\u001b[0m Trial 62 finished with value: 0.01711530052125454 and parameters: {'learning rate': 0.004852837198692055, 'weight decay': 0.01877872841399323, 'epsilon': 0.12939702474656464}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.14357268046587707, Test Loss: 0.01711530052125454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:09,764]\u001b[0m Trial 63 finished with value: 0.027712291106581688 and parameters: {'learning rate': 0.0030425850847649438, 'weight decay': 0.029085336741938052, 'epsilon': 0.12533535726257566}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2832659509032965, Test Loss: 0.027712291106581688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:11,547]\u001b[0m Trial 64 finished with value: 0.056973930448293686 and parameters: {'learning rate': 0.0036143479987506472, 'weight decay': 0.005717355300561145, 'epsilon': 0.07740004119023113}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2348203331232071, Test Loss: 0.056973930448293686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:13,434]\u001b[0m Trial 65 finished with value: 0.07886520028114319 and parameters: {'learning rate': 0.003248252691450926, 'weight decay': 0.01091534350742146, 'epsilon': 0.1693688425208623}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.4177631441503763, Test Loss: 0.07886520028114319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:15,199]\u001b[0m Trial 66 finished with value: 0.039559658616781235 and parameters: {'learning rate': 0.00496852716541102, 'weight decay': 0.02050012198541605, 'epsilon': 0.2517523986468584}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.27957155294716357, Test Loss: 0.039559658616781235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:16,968]\u001b[0m Trial 67 finished with value: 0.17802131175994873 and parameters: {'learning rate': 0.002447162617679732, 'weight decay': 0.01973130776784137, 'epsilon': 0.4072463289331617}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.7279684334993363, Test Loss: 0.17802131175994873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:18,929]\u001b[0m Trial 68 finished with value: 1.7594122886657715 and parameters: {'learning rate': 0.0001085888625773848, 'weight decay': 0.019650847718633527, 'epsilon': 0.05238321107071516}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 4.249105370044708, Test Loss: 1.7594122886657715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:20,776]\u001b[0m Trial 69 finished with value: 0.37312066555023193 and parameters: {'learning rate': 0.0012275265037606353, 'weight decay': 0.011267202001853886, 'epsilon': 0.19432631895604358}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 1.0716786101460456, Test Loss: 0.37312066555023193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:22,597]\u001b[0m Trial 70 finished with value: 0.05753469839692116 and parameters: {'learning rate': 0.0030164122420737287, 'weight decay': 0.0274850698485878, 'epsilon': 0.26049563910615003}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3613934710621834, Test Loss: 0.05753469839692116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:24,468]\u001b[0m Trial 71 finished with value: 0.03430069983005524 and parameters: {'learning rate': 0.00498428069938761, 'weight decay': 0.006985214177650727, 'epsilon': 0.13582026599923736}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.14555026236921548, Test Loss: 0.03430069983005524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:26,207]\u001b[0m Trial 72 finished with value: 0.05898185819387436 and parameters: {'learning rate': 0.003537541899467532, 'weight decay': 0.00652416899755266, 'epsilon': 0.11026950938307109}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.21553257517516614, Test Loss: 0.05898185819387436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:28,013]\u001b[0m Trial 73 finished with value: 0.010977120138704777 and parameters: {'learning rate': 0.004927741232685267, 'weight decay': 0.019978978880396736, 'epsilon': 0.07289962319338454}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.09264215286821127, Test Loss: 0.010977120138704777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:29,868]\u001b[0m Trial 74 finished with value: 0.083982914686203 and parameters: {'learning rate': 0.004696650442044257, 'weight decay': 0.02920422123041146, 'epsilon': 0.5195169595415938}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.48339158594608306, Test Loss: 0.083982914686203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:31,676]\u001b[0m Trial 75 finished with value: 0.030134089291095734 and parameters: {'learning rate': 0.0026069180216161713, 'weight decay': 0.018513026508069443, 'epsilon': 0.07356322508356053}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.24469321258366108, Test Loss: 0.030134089291095734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:33,484]\u001b[0m Trial 76 finished with value: 0.12489791214466095 and parameters: {'learning rate': 0.0024658889615040247, 'weight decay': 0.004747218847942174, 'epsilon': 0.07731250321932387}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3160632882267237, Test Loss: 0.12489791214466095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:35,306]\u001b[0m Trial 77 finished with value: 6.573375225067139 and parameters: {'learning rate': 4.426949607060988e-06, 'weight decay': 0.012868195578662816, 'epsilon': 0.037957712577271194}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 12.372026729583741, Test Loss: 6.573375225067139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:37,140]\u001b[0m Trial 78 finished with value: 0.11703677475452423 and parameters: {'learning rate': 0.0017580272420917543, 'weight decay': 0.0025551096342712196, 'epsilon': 0.02486440053630559}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3635991711169481, Test Loss: 0.11703677475452423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:39,030]\u001b[0m Trial 79 finished with value: 0.021564066410064697 and parameters: {'learning rate': 0.003437311022379435, 'weight decay': 0.018358725610215024, 'epsilon': 0.10102213628142417}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.19604524672031404, Test Loss: 0.021564066410064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:41,282]\u001b[0m Trial 80 finished with value: 0.05936458706855774 and parameters: {'learning rate': 0.0025353107265502274, 'weight decay': 0.01830462594137661, 'epsilon': 0.10521194582200835}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.31746570505201815, Test Loss: 0.05936458706855774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:43,201]\u001b[0m Trial 81 finished with value: 0.01840635947883129 and parameters: {'learning rate': 0.0035965848734742685, 'weight decay': 0.0132179327041113, 'epsilon': 0.06656656315005316}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.13759947717189788, Test Loss: 0.01840635947883129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:45,055]\u001b[0m Trial 82 finished with value: 0.02213248796761036 and parameters: {'learning rate': 0.00348146470135686, 'weight decay': 0.012988827612909763, 'epsilon': 0.062116377405878526}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.18193631563335658, Test Loss: 0.02213248796761036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:46,821]\u001b[0m Trial 83 finished with value: 0.032273706048727036 and parameters: {'learning rate': 0.0036177359968630196, 'weight decay': 0.011728670652388402, 'epsilon': 0.06537874489918054}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2212399175390601, Test Loss: 0.032273706048727036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:48,713]\u001b[0m Trial 84 finished with value: 0.02474682778120041 and parameters: {'learning rate': 0.003104047833739396, 'weight decay': 0.020776289629016308, 'epsilon': 0.0892974012288632}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.18571689426898957, Test Loss: 0.02474682778120041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:50,501]\u001b[0m Trial 85 finished with value: 0.023511847481131554 and parameters: {'learning rate': 0.0036171401092071212, 'weight decay': 0.01398286867776454, 'epsilon': 0.06286322512208103}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.13576178308576345, Test Loss: 0.023511847481131554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:52,247]\u001b[0m Trial 86 finished with value: 0.06934210658073425 and parameters: {'learning rate': 0.0035341012200540796, 'weight decay': 0.013788294862740568, 'epsilon': 0.20954465012491974}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.33439389541745185, Test Loss: 0.06934210658073425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:54,102]\u001b[0m Trial 87 finished with value: 0.05396445095539093 and parameters: {'learning rate': 0.0018757860443459323, 'weight decay': 0.0077349206882452014, 'epsilon': 0.027780890555785698}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.2707043033093214, Test Loss: 0.05396445095539093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:55,924]\u001b[0m Trial 88 finished with value: 0.026153365150094032 and parameters: {'learning rate': 0.0038944294856288024, 'weight decay': 0.01038899351828557, 'epsilon': 0.05733204671066458}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.15785429142415525, Test Loss: 0.026153365150094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:57,678]\u001b[0m Trial 89 finished with value: 0.01782294735312462 and parameters: {'learning rate': 0.0038410538825547754, 'weight decay': 0.010945414810050194, 'epsilon': 0.056616761290055134}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.1412674982100725, Test Loss: 0.01782294735312462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:50:59,511]\u001b[0m Trial 90 finished with value: 5.325339317321777 and parameters: {'learning rate': 2.5906388144158476e-05, 'weight decay': 0.014521926389613193, 'epsilon': 0.09795722856405978}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 10.528656673431396, Test Loss: 5.325339317321777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:01,304]\u001b[0m Trial 91 finished with value: 0.023707764223217964 and parameters: {'learning rate': 0.0037088854427493145, 'weight decay': 0.010081505843134143, 'epsilon': 0.056495108775329025}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.13969579041004182, Test Loss: 0.023707764223217964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:03,111]\u001b[0m Trial 92 finished with value: 0.009885666891932487 and parameters: {'learning rate': 0.004030145189564795, 'weight decay': 0.021871625597739214, 'epsilon': 0.024893395778909415}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.061197773832827804, Test Loss: 0.009885666891932487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:04,870]\u001b[0m Trial 93 finished with value: 0.014911963604390621 and parameters: {'learning rate': 0.0039325123193837755, 'weight decay': 0.009582074240312545, 'epsilon': 0.024799781634501937}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.07231716644018889, Test Loss: 0.014911963604390621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:06,822]\u001b[0m Trial 94 finished with value: 0.07168790698051453 and parameters: {'learning rate': 0.002200991381386091, 'weight decay': 0.0054817245203444874, 'epsilon': 0.020691498450925896}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.3368660341948271, Test Loss: 0.07168790698051453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:08,827]\u001b[0m Trial 95 finished with value: 0.013727203942835331 and parameters: {'learning rate': 0.004109205218589394, 'weight decay': 0.013964280550179689, 'epsilon': 0.03674120578332451}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.09874422261491418, Test Loss: 0.013727203942835331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:10,642]\u001b[0m Trial 96 finished with value: 0.10921739786863327 and parameters: {'learning rate': 0.0014760243490842659, 'weight decay': 0.003097981383001931, 'epsilon': 0.027999093105984352}. Best is trial 61 with value: 0.009599674493074417.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.44947058111429217, Test Loss: 0.10921739786863327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:12,423]\u001b[0m Trial 97 finished with value: 0.009159051813185215 and parameters: {'learning rate': 0.00417260629089144, 'weight decay': 0.022776370530345223, 'epsilon': 0.04453309165648957}. Best is trial 97 with value: 0.009159051813185215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.06700747013092041, Test Loss: 0.009159051813185215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:14,279]\u001b[0m Trial 98 finished with value: 0.00957111269235611 and parameters: {'learning rate': 0.004297168844310529, 'weight decay': 0.02167961106894991, 'epsilon': 0.006967847036147487}. Best is trial 97 with value: 0.009159051813185215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.03962856903672218, Test Loss: 0.00957111269235611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-26 17:51:16,073]\u001b[0m Trial 99 finished with value: 0.009620252065360546 and parameters: {'learning rate': 0.004867305387030955, 'weight decay': 0.022915270062657925, 'epsilon': 0.008829338157094191}. Best is trial 97 with value: 0.009159051813185215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.03165750531479716, Test Loss: 0.009620252065360546\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning rate': 0.00417260629089144,\n",
       " 'weight decay': 0.022776370530345223,\n",
       " 'epsilon': 0.04453309165648957}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training loss : 0.11654255986213684, Test Loss: 0.01178944855928421\n"
     ]
    }
   ],
   "source": [
    "# call the network for training\n",
    "model = MLP()\n",
    "model.weight_init()\n",
    "\n",
    "# set up the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=default_params['learning rate'], weight_decay=default_params['weight decay'], eps=default_params['epsilon'])\n",
    "\n",
    "t1 = pd.Series(feature[130:tr_x.shape[0] +130].index, index=tr_x.index) # look ahead of 130 days\n",
    "cv = PurgedKFold(n_splits=5, t1=t1, pctEmbargo=0.05) \n",
    "\n",
    "train_losses = []\n",
    "for fold_idx, (tr, val) in enumerate(cv.split(tr_x)): # 5-fold Purged Cross Validation\n",
    "    # assign training set and validation set of CV scheme\n",
    "    x_train, y_train = torch.Tensor(tr_x.values[tr]), torch.Tensor(tr_y.values[tr])\n",
    "    x_valid, y_valid = torch.Tensor(tr_x.values[val]), torch.Tensor(tr_y.values[val])\n",
    "    \n",
    "    # for each epoch train and update the network\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get prediction and its loss with gradients\n",
    "        output = model(x_train)\n",
    "        loss = loss_fn(output, y_train)\n",
    "        loss.backward()\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.step()\n",
    "        \n",
    "    # validate model\n",
    "    output = model(x_valid)\n",
    "    valid_loss = loss_fn(output, y_valid)  \n",
    "    train_losses.append(valid_loss.detach().item())  \n",
    "\n",
    "# after training and CV\n",
    "x_test, y_test = torch.Tensor(val_x.values), torch.Tensor(val_y.values)\n",
    "output = model(x_test).detach()\n",
    "test_loss = loss_fn(output, y_test)\n",
    "print(f'Average Training loss : {np.mean(train_losses)}, Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'net_state_dict':model.state_dict(), 'optimizer_dict':optimizer.state_dict()}, '/Users/mac/Desktop/PycharmProjects/TAADL/network/params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
